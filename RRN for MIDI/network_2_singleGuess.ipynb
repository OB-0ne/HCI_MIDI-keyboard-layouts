{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"network_2_singleGuess.ipynb","provenance":[],"collapsed_sections":["43cDNEEBftXz","Yj-DbSNGftX8","hsb0uJP7vxdz"],"authorship_tag":"ABX9TyObwWRazN7JfyMRnL6Sv+lB"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"nAKc0sN8IUjf"},"source":["# 0: Libraries and Functionalities"]},{"cell_type":"code","metadata":{"id":"AkXXqSXogDV8","executionInfo":{"status":"ok","timestamp":1606592100988,"user_tz":300,"elapsed":3254,"user":{"displayName":"Omkar Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsZwFu75wt7Q3LYtVgRRB-FoHMwI-iNat405Z6=s64","userId":"08161527270585092155"}}},"source":["#import all the needed libraries and initialize them\n","\n","import pandas as pd\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import random\n","import time\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","\n","#playing audio\n","import IPython.display as ipd"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"39LlzDiCRu68","executionInfo":{"status":"ok","timestamp":1606592100989,"user_tz":300,"elapsed":3248,"user":{"displayName":"Omkar Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsZwFu75wt7Q3LYtVgRRB-FoHMwI-iNat405Z6=s64","userId":"08161527270585092155"}}},"source":["class StopWatch():\n","\n","    def __init__(self):\n","        self.start_time = time.time()\n","\n","    def give(self):\n","        time_diff = round(time.time() - self.start_time)\n","        hour = str(time_diff // 3600).zfill(2)\n","        minute = str((time_diff % 3600) // 60).zfill(2)\n","        second = str(time_diff % 60).zfill(2)  # Same as time_diff - (minutes * 60)\n","        \n","        return f'[{hour}:{minute}:{second}]'\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"o3KTgtahCiYz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606592119377,"user_tz":300,"elapsed":21628,"user":{"displayName":"Omkar Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsZwFu75wt7Q3LYtVgRRB-FoHMwI-iNat405Z6=s64","userId":"08161527270585092155"}},"outputId":"6ab7bf47-76d6-4cbb-b55d-e53be330f9bc"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jUD16OodDmFE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606592119379,"user_tz":300,"elapsed":21625,"user":{"displayName":"Omkar Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsZwFu75wt7Q3LYtVgRRB-FoHMwI-iNat405Z6=s64","userId":"08161527270585092155"}},"outputId":"29d7b3ff-1e9e-47e3-ded9-7730ce59d33f"},"source":["%cd 'drive/My Drive/Music + AI Project/04 - [NN2] RRN for MIDI'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Music + AI Project/04 - [NN2] RRN for MIDI\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LGyI4L7DA-8i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606592123182,"user_tz":300,"elapsed":24528,"user":{"displayName":"Omkar Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsZwFu75wt7Q3LYtVgRRB-FoHMwI-iNat405Z6=s64","userId":"08161527270585092155"}},"outputId":"1deca695-5045-449f-d63b-0d193fffa8b4"},"source":["pip install mido"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Collecting mido\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/0a/81beb587b1ae832ea6a1901dc7c6faa380e8dd154e0a862f0a9f3d2afab9/mido-1.2.9-py2.py3-none-any.whl (52kB)\n","\r\u001b[K     |██████▎                         | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 20kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 30kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 51kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.3MB/s \n","\u001b[?25hInstalling collected packages: mido\n","Successfully installed mido-1.2.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x2QdiSJZHpe0","executionInfo":{"status":"ok","timestamp":1606592123399,"user_tz":300,"elapsed":22100,"user":{"displayName":"Omkar Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsZwFu75wt7Q3LYtVgRRB-FoHMwI-iNat405Z6=s64","userId":"08161527270585092155"}}},"source":["import mido\n","import numpy as np\n","\n","class DataManager():\n","    \n","    \n","    def npFile2MIDI(self, in_filename, out_filename, num = 4, den = 4, clocks = 36, noted32 = 8, AutoTimed = False, AutoTime=120):\n","            \n","        max_midi_time = 1000.0\n","\n","        data = np.load(in_filename)\n","        mid = mido.MidiFile()\n","        track = mido.MidiTrack()\n","\n","        mid.tracks.append(track)\n","        \n","        num = 4\n","        den = 4\n","        clocks = 36\n","        noted32 = 8\n","\n","        track.append(mido.MetaMessage('time_signature', numerator=num, denominator=den, clocks_per_click=clocks, notated_32nd_notes_per_beat=noted32, time=0))\n","        test=[]\n","\n","        for msg in data:\n","\n","            if int(msg[0]+0.5) == 1:\n","                control = 'note_on'\n","            else:\n","                control = 'note_off'\n","            \n","            if AutoTimed:\n","                track.append(mido.Message(control, note=int(msg[1]*127), velocity=int(msg[2]*127), time=AutoTime))\n","                \n","            else:\n","                track.append(mido.Message(control, note=int(msg[1]*127), velocity=int(msg[2]*127), time=int(msg[3]*max_midi_time)))\n","\n","        if not out_filename[-4] == '.mid':\n","            out_filename += '.mid'\n","\n","        mid.save(out_filename)\n","\n","    def np2MIDI(self, np_track, out_filename, num = 4, den = 4, clocks = 36, noted32 = 8, AutoTimed = False, AutoTime=120):\n","            \n","        max_midi_time = 1000.0\n","\n","        data = np_track\n","        mid = mido.MidiFile()\n","        track = mido.MidiTrack()\n","\n","        mid.tracks.append(track)\n","        \n","        num = 4\n","        den = 4\n","        clocks = 36\n","        noted32 = 8\n","\n","        track.append(mido.MetaMessage('time_signature', numerator=num, denominator=den, clocks_per_click=clocks, notated_32nd_notes_per_beat=noted32, time=0))\n","        test=[]\n","\n","        for msg in data:\n","\n","            if int(msg[0]+0.5) == 1:\n","                control = 'note_on'\n","            else:\n","                control = 'note_off'\n","            \n","            if AutoTimed:\n","                track.append(mido.Message(control, note=int(msg[1]*127), velocity=int(msg[2]*127), time=AutoTime))\n","                \n","            else:\n","                track.append(mido.Message(control, note=int(msg[1]*127), velocity=int(msg[2]*127), time=int(msg[3]*max_midi_time)))\n","\n","        if not out_filename[-4] == '.mid':\n","            out_filename += '.mid'\n","\n","        mid.save(out_filename)\n","\n","    def MIDIFile2np(self, in_filename, out_filname):\n","        max_midi_time = 1000.0\n","\n","        def standardizeData(midiData):\n","            for msg in midiData:\n","                msg[1] = float(msg[1])/127.0\n","                msg[2] = float(msg[2])/127.0\n","                msg[3] = float(msg[3])/max_midi_time\n","            return midiData\n","\n","\n","        mid = mido.MidiFile(in_filename)\n","\n","        i = 0\n","        mid_out = []\n","\n","        for i,track in enumerate(mid.tracks):\n","                \n","            for msg in track:\n","\n","                if msg.type == \"control_change\":\n","                    #skip for now I guess\n","                    continue\n","                elif msg.type == \"note_on\":\n","                    mid_out.append([1,msg.note,msg.velocity,msg.time])\n","                elif msg.type == \"note_off\":\n","                    mid_out.append([0,msg.note,msg.velocity,msg.time])\n","\n","            mid_out = np.array(standardizeData(mid_out))\n","            np.save(out_filname + str(i),np.array(mid_out))\n","\n","\n"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tusfkPPlftXR"},"source":["# 4: The Neural Network (Sample Output)"]},{"cell_type":"markdown","metadata":{"id":"Ui5GqhFwftXX"},"source":["## 4.1: Reading features"]},{"cell_type":"code","metadata":{"id":"5VAa7cAPftXa","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1601966583019,"user_tz":240,"elapsed":597,"user":{"displayName":"Omkar Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsZwFu75wt7Q3LYtVgRRB-FoHMwI-iNat405Z6=s64","userId":"08161527270585092155"}},"outputId":"77cd9579-295b-45e5-9176-ba875d81f398"},"source":["#read the fetures if not in memeory\n","all_feature_matrix = np.load(\"midiTest.npy\")\n","print(\"MIDI Reading Completed!\")\n","print(\"Shape of the features: \", all_feature_matrix.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MIDI Reading Completed!\n","Shape of the features:  (4264, 4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vqwUzCw7ftXk"},"source":["## 4.2: Setting NN Variables and Define Model"]},{"cell_type":"code","metadata":{"id":"j3lLIXMzEsTG"},"source":["def save_checkpoint(net, optimizer, epoch_no, loss, checkpoint_name=\"\", store_eNum = True):\n","\n","    path = \"saved_net/\"\n","    if checkpoint_name == \"\":\n","        path = path + \"checkpoint_e\" + str(epoch_no+1) + \".pt\"\n","    else:\n","        path = path + checkpoint_name\n","        if store_eNum:\n","            path = path + \"_e\" + str(epoch_no+1)\n","        path += \".pt\"\n","\n","    checkpoint = {}\n","    checkpoint = {'epoch': epoch_no,\n","                    'model_state_dict': net.state_dict(),\n","                    'optimizer_state_dict': optimizer.state_dict(),\n","                    'loss': loss,\n","                    'meta': update_nn_metaData()\n","                  }\n","\n","    torch.save(checkpoint, path)\n","\n","    print(f\"----- Saved the network as '{path}' -----\")\n","\n","def load_checkpoint(net, optimizer, checkpoint_name, net_evalMode = False):\n","\n","    path = \"saved_net/\"\n","    path = path + checkpoint_name + \".pt\"\n","\n","    checkpoint = torch.load(path)\n","\n","    net.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    epoch_no = checkpoint['epoch']\n","    loss = checkpoint['loss']\n","    nn_meta = checkpoint['meta']\n","\n","    apply_nn_metaData(nn_meta)\n","\n","    if net_evalMode:\n","        net.eval()\n","    else:\n","        net.train()\n","\n","    print(f\"----- Loaded the network from '{path}' -----\")\n","\n","    return net, optimizer, epoch_no, loss\n","\n","def apply_nn_metaData(nn_meta):\n","\n","    input_size = nn_meta['input_size']\n","    midi_features = nn_meta['midi_features']\n","    feature_size = nn_meta['feature_size']\n","    hidden_size = nn_meta['hidden_size']\n","    output_size = nn_meta['output_size']\n","    num_layers = nn_meta['num_layers']\n","    dropout_per = nn_meta['dropout_per']\n","    learning_rate = nn_meta['learning_rate']\n","    batch_size = nn_meta['batch_size']\n","\n","def update_nn_metaData():\n","\n","    nn_meta = {}\n","\n","    nn_meta['input_size'] = input_size\n","    nn_meta['midi_features'] = midi_features\n","    nn_meta['feature_size'] = feature_size\n","    nn_meta['hidden_size'] = hidden_size\n","    nn_meta['output_size'] = output_size\n","    nn_meta['num_layers'] = num_layers\n","    nn_meta['dropout_per'] = dropout_per\n","    nn_meta['learning_rate'] = learning_rate\n","    nn_meta['batch_size'] = batch_size\n","\n","    return nn_meta\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lf6CO7o7ftXm"},"source":["**Variables**:\n","\n","Variable name | Description | Can I change this?\n","--- | --- | ---\n","sr | sampling rate at which the song has been read at, and helps in setting network nodes | Yes (Keep consistent with input)\n","batch_num | how many batches should a chunk be converted into? | Yes\n","input_size | calculates the input layer nodes for the network | No\n","hidden_size | calculates the hidden layer nodes for the network | Yes (Only the factor)\n","output_size | calculates the output layer nodes for the network | Yes (Depends on network check)\n","num_layers | setting default layers to 1 for now | No\n","dropout_per | what percent of the layers need to be droped while training | Yes\n","learning_rate | the rate at which the network learns outputs | Yes (exponent form)"]},{"cell_type":"code","metadata":{"id":"iO1D0McWftXn"},"source":["# Setting up variables for the neural networks\n","input_size = 20\n","midi_features = 4\n","feature_size = midi_features * input_size\n","hidden_size = int(feature_size*2.2)\n","output_size = midi_features\n","num_layers = 5\n","dropout_per = 0.65\n","learning_rate = 1e-3\n","batch_size = 100\n","\n","# setting the device to run the code to GPU is avaialble\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"THPWdjIKIQ82"},"source":["# definfng the Neural network class\n","class MidiRNN(nn.Module):\n","\n","    # initializaing the network\n","    # declaring all the needed layers\n","    def __init__(self):\n","        super(MidiRNN,self).__init__()\n","\n","        # an lstm layer for input to hidden layers\n","        self.rnn = nn.LSTM(feature_size, hidden_size, num_layers)\n","        # hidden to putput\n","        self.out = nn.Linear(hidden_size, output_size)\n","        # a dropdout layer between the hideen and output layer \n","        self.drop = nn.Dropout(p=dropout_per)\n","\n","        # making the hidden layer and setting it to zero\n","        self.hidden = ((torch.zeros(num_layers, 1, hidden_size)), (torch.zeros(num_layers, 1, hidden_size)))\n","\n","    def reset_hidden(self):\n","        # resetting the hidden layer to zero, which can be done after backpropogation\n","        self.hidden = ((torch.zeros(num_layers, 1, hidden_size)), (torch.zeros(num_layers, 1, hidden_size)))\n","\n","    #setting the network layers in order\n","    def forward(self, seq):\n","        # here, the view is adding anoher dimention to the sequence being passed to the network\n","        out, self.hidden = self.rnn(seq.view(1,1,-1))\n","        # out, self.hidden = self.rnn(seq.view(1,feature_size,-1))\n","        out = self.drop(out)\n","        # out = self.out(out.view(1,-1))\n","        out = self.out(out)\n","\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"43cDNEEBftXz"},"source":["## 4.3: Validate the Model"]},{"cell_type":"code","metadata":{"id":"L5edjmUmftXz"},"source":["def validate_network(showError = False):\n","\n","    # making a list of all the batch number which belong to the testing groups\n","    test_list = [x for x in range(total_train,total_train+total_test)]\n","    loss_by_batch = []\n","\n","    # setting the network t evaluation\n","    net.eval()\n","\n","    # iterate through the testing bacthes\n","    for i in range(total_train,total_train + total_test - input_size - 1):\n","\n","        # set loss to to zero after each batch iteration\n","        loss = 0\n","\n","        # get the needed input and actual output values \n","        input_matrix = torch.FloatTensor(all_feature_matrix[i:i + input_size]).to(device)\n","        val_output = torch.FloatTensor(np.array(all_feature_matrix[i+input_size+1])).to(device)\n","\n","        # get the network output\n","        nn_output = net(input_matrix)\n","\n","        # check the network output and add the loss\n","        loss += loss_function(nn_output, val_output)\n","\n","        # add the loss to a list which contains loss for all batches\n","        loss_by_batch.append(loss)\n","\n","    # plot the graph of the batch loss as a line graph\n","    if showError:\n","        plt.plot(loss_by_batch)\n","        plt.ylabel('Loss by batch')\n","        plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Moysn3cLftX4"},"source":["## 4.4: Generate some Music"]},{"cell_type":"code","metadata":{"id":"qn2QouzGftX5"},"source":["def generate_sample_song(song_length_seconds, song_name = \"test_output.wav\", showSignal = False, saveMIDI = False, saveNumpy = True, seed = 35):\n","\n","    # variables for the song output\n","    total_iterations = song_length_seconds\n","\n","    # get the features for the seed\n","    input_seed = torch.FloatTensor(all_feature_matrix[seed:seed+input_size]).to(device)\n","\n","    # make a zero variable to input the song into\n","    song = np.zeros((song_length_seconds,4))\n","    song[0:input_size] = input_seed.cpu().detach().numpy()\n","\n","    # set the network to evaluation mode\n","    net.eval()\n","\n","    # loop through the needed iterations\n","    for i in range(total_iterations-input_size):\n","\n","        input_seed = torch.FloatTensor(song[i:input_size + i]).to(device)\n","\n","        # get the output from the network\n","        nn_output = net(input_seed)\n","\n","        # add the current output to the song\n","        song[input_size + i] = nn_output.cpu().detach().numpy()\n","\n","    if saveNumpy:\n","        np.save(song_name,np.array(song))\n","\n","    if saveMIDI:\n","        DM = DataManager()\n","        DM.np2MIDI(song, song_name,AutoTimed=True)\n","        \n","\n","def generate_sample_song_random(song_length_midi, total_midi,  song_name = \"test_output.wav\", showSignal = False, saveMIDI = False, saveNumpy = True, seed = 35):\n","\n","    # variables for the song output\n","    total_iterations = song_length_midi\n","\n","    # set the network to evaluation mode\n","    net.eval()\n","\n","    for j in range(total_midi):\n","        \n","\n","        # get the features for the seed\n","        input_seed = torch.FloatTensor(all_feature_matrix[seed:seed+input_size]).to(device)\n","\n","        # make a zero variable to input the song into\n","        song = np.zeros((song_length_midi,4))\n","        song[0:input_size] = input_seed.cpu().detach().numpy()\n","\n","\n","        # loop through the needed iterations\n","        for i in range(total_iterations-input_size):\n","\n","            input_seed = torch.FloatTensor(song[i:input_size + i]).to(device)\n","\n","            # get the output from the network\n","            nn_output = net(input_seed)\n","\n","            # add the current output to the song\n","            song[input_size + i] = nn_output.cpu().detach().numpy()\n","\n","    if saveNumpy:\n","        np.save(song_name,np.array(song))\n","\n","    if saveMIDI:\n","        DM = DataManager()\n","        DM.np2MIDI(song, song_name,AutoTimed=True)\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yj-DbSNGftX8"},"source":["## 4.5: Train the Model"]},{"cell_type":"code","metadata":{"id":"KSkTsvm8ftX-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"error","timestamp":1601966597784,"user_tz":240,"elapsed":3415,"user":{"displayName":"Omkar Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsZwFu75wt7Q3LYtVgRRB-FoHMwI-iNat405Z6=s64","userId":"08161527270585092155"}},"outputId":"0359145f-2521-4f11-d764-a00732f74259"},"source":["# set the number of epoch and traininng perecntage of the dataset\n","epochs = 2000\n","training_per = 0.9\n","test_network = 10\n","start_epoch = 0\n","\n","# load a checkpoint\n","load = True\n","checkpoint_name = \"checkpoint_e50\"\n","\n","# this calculates the total number of chucks to be used for training and testing\n","total_train = int(all_feature_matrix.shape[0] * training_per)\n","total_test = all_feature_matrix.shape[0] - total_train\n","\n","#get total batch sizes and math around it\n","total_batches = math.ceil(total_train/batch_size)\n","\n","# make the network and put it on GPU\n","net = MidiRNN().float().to(device)\n","\n","# define an optimizer and loss function\n","# this can be changed as per the model\n","optimizer = torch.optim.Adamax(net.parameters(), lr=learning_rate)\n","loss_function = nn.MSELoss()\n","\n","# making a stopwatch to count time\n","watch = StopWatch()\n","\n","if load:\n","    net, optimizer, start_epoch, loss = load_checkpoint(net,optimizer,checkpoint_name)\n","    start_epoch = start_epoch + 1\n","\n","# loop for all the epochs\n","for epoch in range(start_epoch,epochs):\n","\n","    # reset the epoch loss\n","    epoch_loss = 0\n","\n","    for batch in range(total_batches):\n","        # reset the hidden layers and remove all gradients after each batch iteration, which also considers back propogation\n","        net.reset_hidden()\n","        net.zero_grad()\n","        loss = 0 \n","\n","        batch_start = max((batch * batch_size) - input_size,0)\n","        batch_end = max(((batch+1) * batch_size),total_train) - input_size\n","\n","        # run for all the chunks\n","        for i in range(batch_start, batch_end):\n","                \n","            # make the input and validation output tensors\n","            input_matrix = torch.FloatTensor(all_feature_matrix[i:i + input_size]).to(device)\n","            val_output = torch.FloatTensor(np.array(all_feature_matrix[i+input_size+1])).to(device)\n","\n","            # get the network output\n","            nn_output = net(input_matrix)\n","\n","            # calculate the loss from the nnetwork output and valid output\n","            # print(nn_output, val_output)\n","            # print(val_output.view(1,-1))\n","            loss += loss_function(nn_output, val_output.view(1,1,-1))\n","            epoch_loss += loss\n","\n","        # back propogate through the network with the accumulated error and optimizer\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (batch+1) % 5 == 0:\n","            # a print to now the end of an epoch and its loss\n","            print(f'{watch.give()} Epoch {epoch + 1} Batch {batch + 1} Batch Loss: {round(float(loss),6)}')\n","\n","    # a print to now the end of an epoch and its loss\n","    print(f'{watch.give()} Epoch {epoch + 1} completed! Total Loss: {round(float(epoch_loss),6)}')\n","\n","    # after a few epochs check with the testing of the network and also generate a song sample\n","    if (epoch+1) % test_network == 0:\n","        validate_network(True)\n","        generate_sample_song(1000, f'outputs/midi_e{epoch+1}',saveMIDI = True)\n","        save_checkpoint(net,optimizer,epoch,loss)\n","        net.train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----- Loaded the network from 'saved_net/checkpoint_e50.pt' -----\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-d0490a254943>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# get the network output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# calculate the loss from the nnetwork output and valid output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-eeb470e3925c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# here, the view is adding anoher dimention to the sequence being passed to the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m# out, self.hidden = self.rnn(seq.view(1,feature_size,-1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 577\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"hsb0uJP7vxdz"},"source":["## 4.5: Run-Only Model\n","\n","(Makes MIDI on the go!)"]},{"cell_type":"code","metadata":{"id":"CavxUi9Xv2i0","colab":{"base_uri":"https://localhost:8080/","height":586},"executionInfo":{"status":"ok","timestamp":1601967171773,"user_tz":240,"elapsed":1159,"user":{"displayName":"Omkar Bhatt","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjsZwFu75wt7Q3LYtVgRRB-FoHMwI-iNat405Z6=s64","userId":"08161527270585092155"}},"outputId":"13043200-ab65-4b3f-b156-3d01d1a6aaa3"},"source":["# set loading values as variables\n","sample_MIDI_size = 40\n","total_samples = 30\n","total_seeds = all_feature_matrix.shape[0]//input_size\n","\n","# load a checkpoint\n","checkpoint_name = \"checkpoint_e50\"\n","\n","watch = StopWatch()\n","\n","net, _, _, _ = load_checkpoint(net,optimizer,checkpoint_name)\n","\n","for i in range(total_samples):\n","    generate_sample_song(sample_MIDI_size, f'outputs_run/sample_{(i+1):02d}',saveMIDI = True, saveNumpy=False, seed=random.randint(0, total_seeds))\n","    print(f'{watch.give()} sample_{(i+1):02d} generated')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----- Loaded the network from 'saved_net/checkpoint_e50.pt' -----\n","[00:00:00] sample_01 generated\n","[00:00:00] sample_02 generated\n","[00:00:00] sample_03 generated\n","[00:00:00] sample_04 generated\n","[00:00:00] sample_05 generated\n","[00:00:00] sample_06 generated\n","[00:00:00] sample_07 generated\n","[00:00:00] sample_08 generated\n","[00:00:00] sample_09 generated\n","[00:00:00] sample_10 generated\n","[00:00:00] sample_11 generated\n","[00:00:00] sample_12 generated\n","[00:00:00] sample_13 generated\n","[00:00:00] sample_14 generated\n","[00:00:01] sample_15 generated\n","[00:00:01] sample_16 generated\n","[00:00:01] sample_17 generated\n","[00:00:01] sample_18 generated\n","[00:00:01] sample_19 generated\n","[00:00:01] sample_20 generated\n","[00:00:01] sample_21 generated\n","[00:00:01] sample_22 generated\n","[00:00:01] sample_23 generated\n","[00:00:01] sample_24 generated\n","[00:00:01] sample_25 generated\n","[00:00:01] sample_26 generated\n","[00:00:01] sample_27 generated\n","[00:00:01] sample_28 generated\n","[00:00:01] sample_29 generated\n","[00:00:01] sample_30 generated\n"],"name":"stdout"}]}]}